require('dotenv').config({ path: '.env.local' })
const { createClient } = require('@supabase/supabase-js')

function parseArgs() {
  const args = process.argv.slice(2)
  const config = {
    baseUrl: process.env.TEST_BASE_URL || process.env.NEXT_PUBLIC_SITE_URL || 'http://localhost:3005',
    limit: process.env.ANALYTICS_LIMIT ? Number(process.env.ANALYTICS_LIMIT) : undefined,
  }
  for (let i = 0; i < args.length; i += 1) {
    const a = args[i]
    if (a === '--base' && args[i + 1]) {
      config.baseUrl = args[i + 1]
      i += 1
    } else if (a === '--limit' && args[i + 1]) {
      const v = Number(args[i + 1])
      if (!Number.isNaN(v) && v > 0) config.limit = v
      i += 1
    }
  }
  return config
}

// Initialize Supabase client
const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
)

async function batchGenerateAnalytics() {
  try {
    console.log('üßÆ Starting batch analytics generation for all California judges...')
    const config = parseArgs()
    
    // Get all California judges with case counts
    const { data: judges, error: judgesError } = await supabase
      .from('judges')
      .select('id, name, total_cases')
      .eq('jurisdiction', 'CA')
      .order('name')
    
    if (judgesError) {
      throw new Error(`Failed to fetch judges: ${judgesError.message}`)
    }
    
    console.log(`üìä Found ${judges.length} California judges for analytics generation`)
    
    // Filter judges with cases (should have cases if seeding was successful)
    const judgesWithCases = judges.filter(judge => judge.total_cases && judge.total_cases > 0)
    const judgesWithoutCases = judges.filter(judge => !judge.total_cases || judge.total_cases === 0)
    
    console.log(`‚úÖ ${judgesWithCases.length} judges have case data`)
    console.log(`‚ö†Ô∏è  ${judgesWithoutCases.length} judges have no case data`)
    
    if (judgesWithoutCases.length > 0) {
      console.log('\nJudges without cases:')
      judgesWithoutCases.slice(0, 5).forEach(judge => {
        console.log(`   - ${judge.name} (${judge.total_cases || 0} cases)`)
      })
      if (judgesWithoutCases.length > 5) {
        console.log(`   ... and ${judgesWithoutCases.length - 5} more`)
      }
    }
    
    // Start analytics generation
    if (typeof config.limit === 'number') {
      console.log(`‚úÇÔ∏è  Limiting to first ${config.limit} judges for this run`)
    }
    const targetJudges = typeof config.limit === 'number' ? judgesWithCases.slice(0, config.limit) : judgesWithCases

    console.log(`\nüöÄ Starting analytics generation for ${targetJudges.length} judges with case data...`)
    
    let successCount = 0
    let errorCount = 0
    let skippedCount = 0
    
    // Process in smaller batches to avoid overwhelming the system
    const batchSize = 10
    for (let i = 0; i < targetJudges.length; i += batchSize) {
      const judgeBatch = targetJudges.slice(i, i + batchSize)
      const batchNumber = Math.ceil((i + 1) / batchSize)
      const totalBatches = Math.ceil(targetJudges.length / batchSize)
      
      console.log(`\nüì¶ Processing batch ${batchNumber}/${totalBatches} (${judgeBatch.length} judges)`)
      
      // Process batch concurrently but with timeout
      const batchPromises = judgeBatch.map(async (judge, index) => {
        try {
          const startTime = Date.now()
          console.log(`   ${i + index + 1}/${targetJudges.length} - Generating analytics for ${judge.name}...`)
          
          // Check if analytics already exist and are recent
          const { data: existingCache } = await supabase
            .from('judge_analytics_cache')
            .select('created_at')
            .eq('judge_id', judge.id)
            .single()
          
          if (existingCache) {
            const cacheAge = Date.now() - new Date(existingCache.created_at).getTime()
            const hoursSinceCache = cacheAge / (1000 * 60 * 60)
            
            if (hoursSinceCache < 24) { // Skip if cached within last 24 hours
              console.log(`   ‚è≠Ô∏è  Skipping ${judge.name} - analytics cached ${Math.round(hoursSinceCache)}h ago`)
              return { status: 'skipped', judge: judge.name, reason: 'recent_cache' }
            }
          }
          
          // Generate analytics by calling the API endpoint
          const baseUrl = config.baseUrl
          
          const response = await fetch(`${baseUrl}/api/judges/${judge.id}/analytics`, {
            method: 'GET',
            headers: {
              'Content-Type': 'application/json'
            },
            timeout: 30000 // 30 second timeout
          })
          
          if (!response.ok) {
            throw new Error(`API responded with status ${response.status}`)
          }
          
          const analyticsData = await response.json()
          const duration = Date.now() - startTime
          
          console.log(`   ‚úÖ Generated analytics for ${judge.name} (${duration}ms, ${analyticsData.analytics.total_cases_analyzed} cases, ${analyticsData.analytics.overall_confidence}% confidence)`)
          
          return { 
            status: 'success', 
            judge: judge.name, 
            cases: analyticsData.analytics.total_cases_analyzed,
            confidence: analyticsData.analytics.overall_confidence,
            quality: analyticsData.analytics.analysis_quality,
            duration 
          }
          
        } catch (error) {
          console.log(`   ‚ùå Failed to generate analytics for ${judge.name}: ${error.message}`)
          return { status: 'error', judge: judge.name, error: error.message }
        }
      })
      
      // Wait for batch to complete
      const batchResults = await Promise.all(batchPromises)
      
      // Count results
      batchResults.forEach(result => {
        switch (result.status) {
          case 'success': successCount++; break
          case 'error': errorCount++; break
          case 'skipped': skippedCount++; break
        }
      })
      
      console.log(`   üìä Batch ${batchNumber} completed: ${batchResults.filter(r => r.status === 'success').length} success, ${batchResults.filter(r => r.status === 'error').length} errors, ${batchResults.filter(r => r.status === 'skipped').length} skipped`)
      
      // Small delay between batches to avoid overwhelming the system
      if (i + batchSize < judgesWithCases.length) {
        console.log('   ‚è≥ Waiting 3 seconds before next batch...')
        await new Promise(resolve => setTimeout(resolve, 3000))
      }
    }
    
    console.log('\nüéâ Batch analytics generation completed!')
    console.log(`üìà Results summary:`)
    console.log(`   ‚úÖ Successful: ${successCount}`)
    console.log(`   ‚ùå Errors: ${errorCount}`)
    console.log(`   ‚è≠Ô∏è  Skipped (cached): ${skippedCount}`)
    console.log(`   üìä Total processed: ${successCount + errorCount + skippedCount}`)
    
    // Generate summary statistics
    if (successCount > 0) {
      const { data: analyticsStats } = await supabase
        .from('judge_analytics_cache')
        .select('analytics')
        .limit(100)
      
      if (analyticsStats && analyticsStats.length > 0) {
        const avgConfidence = analyticsStats.reduce((sum, item) => 
          sum + (item.analytics?.overall_confidence || 0), 0) / analyticsStats.length
        
        const avgCases = analyticsStats.reduce((sum, item) => 
          sum + (item.analytics?.total_cases_analyzed || 0), 0) / analyticsStats.length
        
        console.log(`\nüìä Analytics quality overview (sample of ${analyticsStats.length} judges):`)
        console.log(`   üìà Average confidence: ${Math.round(avgConfidence)}%`)
        console.log(`   üìã Average cases analyzed: ${Math.round(avgCases)}`)
        
        const qualityDistribution = analyticsStats.reduce((acc, item) => {
          const quality = item.analytics?.analysis_quality || 'unknown'
          acc[quality] = (acc[quality] || 0) + 1
          return acc
        }, {})
        
        console.log(`   üè∑Ô∏è  Quality distribution:`)
        Object.entries(qualityDistribution).forEach(([quality, count]) => {
          console.log(`      ${quality}: ${count} judges`)
        })
      }
    }
    
    if (errorCount > 0) {
      console.log(`\n‚ö†Ô∏è  ${errorCount} judges had errors during analytics generation`)
      console.log('Consider running the script again to retry failed judges')
    }
    
  } catch (error) {
    console.error('üí• Error during batch analytics generation:', error.message)
    process.exit(1)
  }
}

// Run the batch generation
if (require.main === module) {
  batchGenerateAnalytics()
    .then(() => {
      console.log('‚ú® Batch analytics generation process completed!')
      process.exit(0)
    })
    .catch((error) => {
      console.error('üí• Batch analytics generation failed:', error)
      process.exit(1)
    })
}

module.exports = { batchGenerateAnalytics }